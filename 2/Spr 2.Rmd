---
title: "Spr 2 - ASzCz"
author: "Me"
date: "2023-04-27"
output:
  pdf_document: 
    toc: true
    number_sections: true
    extra_dependencies: ["polski", "mathtools", "amsthm", "amssymb", "icomma", "upgreek", "xfrac", "scrextend", "float", "tabularx", "hyperref", "caption", "enumitem", "titlesec", "animate"]
fontsize: 12pt
---

\renewcommand{\figurename}{Wykres}
\renewcommand{\tablename}{Tablica}
\raggedbottom
\titlelabel{\thetitle.\quad}


```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, eval = TRUE, fig.pos = "H", dev.args=list(encoding="CP1257.enc"), fig.path='figure/', fig.align='center', fig.pos='H',fig.width=5, fig.height=3)
```

```{r, echo=FALSE}
library(EnvStats)
library(xtable)
library(ggplot2)
library(dplyr)
library(tidyr)
library(vcd)
library(knitr)
library(ggpubr)
library(scatterplot3d)
library(corrplot)
#library(forcats)
library(forecast)
library(kableExtra)
#library(tinytex)
#library(janitor)
library(ramify)
#library(ExPosition)
library(TSAFBook)
library(fpp)
library(animation)
library(quantmod)
```


\newpage
\section{Dekompozycja szeregów czasowych -- eliminacja trendu i sezonowości.}
\subsection{Wprowadzenie i analiza graficzna.}
W pierwszej części sprawozdania zajmiemy się dekompozycją szeregu czasowego, w celu eliminacji sezonowości i trendu, oraz porównamy różne jej metody. W tym celu wykorzystaliśmy zbiór danych \verb|energia| (w postaci zmiennej typu \verb|ts|) z pakietu \verb|TSAFBook|, zawierający dane odnoście miesięcznej produkcji energii elektrycznej w Polsce. Dodatkowo, wszystkie wykowywane testy były na poziomie ufności $\alpha=0.05$. Dane pochodzą z okresu styczeń 2008 - sierpień 2014. Na wykresie prezentują się następująco.
```{r, results="asis", fig.cap="Przedstawienie analizowanych danych na wykresie."}
autoplot(energia)
```
Na wykresie widać zachowanie sezonowe, których okres pokrywa się z okresem podanym wraz z danymi wynoszącym `r frequency(energia)`. Przyjrzyjmy się dlatego jeszcze wykresowi sezonowemu.
```{r, results="asis", fig.cap="\\label{fig:seasonplot}Przedstawienie analizowanych danych na wykresie sezonowym."}
ggseasonplot(energia, col=rainbow(7),main = "")
```
Analizując powyższe wykresy widzimy zachowanie sezonowe, natomiast nie możemy z pewnością stwierdzić nic odnośnie istnienia trendu. Wariancja wydaje się jednorodna, jednak znajdują się dane, które odstają delikatnie od normy. Przykładowo, na wykresie sezonowym dla 2012 roku (jasnoniebieska linia), widać nietypowe zachowanie na początku roku. W lutym brakuje spadku, który zostałby skompensowany w marcu.
\subsection{Dekompozycja.}
\subsubsection{Na podstawie ruchomej średniej.}
Na pierwszy ognień weźmiemy dekompozycję przy użyciu funkcji \verb|decompose| z pakietu \verb|stats|. Dekompozycję wykonamy dwukrotnie, początkowo zakładając, że mamy model addytywny, a za drugim razem multiplikatywny.

```{r, results="asis", fig.height=4, fig.cap="Dekompozycja przy założeniu modelu addytywnego."}
autoplot(decompose(energia), main="")
#autoplot(decompose(BoxCox(energia,lambda="auto")), main="")

```

```{r, results="asis", fig.height=4, fig.cap="Dekompozycja przy założeniu modelu multiplikatywnego."}
autoplot(decompose(energia, type="multiplicative"), main="")
```

```{r, results="hide"}
odstajace<-function(X,q){
  iq=iqr(X, na.rm=T)
  res=sum(X>quantile(X,0.75, na.rm=T)+q*iq, na.rm=T)+sum(X<quantile(X,0.25, na.rm=T)-q*iq, na.rm=T)
  res
}
odst.list<-function(q){
  c(odstajace(decompose(energia, type="additive")$random,q),
    odstajace(decompose(energia, type="multiplicative")$random,q),
    odstajace(decompose(BoxCox(energia,lambda="auto"))$random,q),
    odstajace(decompose(BoxCox(energia,lambda=0))$random,q))
}
#odstajace(decompose(energia, type="multiplicative")$random,1.5)




q=1
tmp.a=odstajace(decompose(energia,type="additive")$random,q)
tmp.m=odstajace(decompose(energia,type="multiplicative")$random,q)

#tmp.a=decompose(energia,type="additive")$random
#tmp.m=decompose(energia,type="multiplicative")$random
#tmp.b=decompose(BoxCox(energia,lambda="auto"))$random
#tmp.b0=decompose(BoxCox(energia,lambda=0))$random

tmp=decompose(energia,type="additive")$random
rat.a=max(abs(tmp), na.rm = T)/mean(abs(tmp), na.rm=T)
tmp=decompose(energia,type="multiplicative")$random - 1 # - 1, bo odejmujemy średnią (w przybliżeniu od 4/5 miejsca po przecinki) 
rat.m=max(abs(tmp), na.rm = T)/mean(abs(tmp), na.rm=T)

```
Oba przypadki wyglądają bardzo podobnie, jeśli przyjrzymy się obserwacją odstającym w otrzymanych residuach, to zauważymy, że w przypadku addytywnym otrzymaliśmy `r tmp.a` obserwacji odstających, a w przypadku multiplikatywnym `r tmp.m`. Za obserwacje odstające $y$ uznaliśmy te, które spełniają $y\not\in(Q_1-$ `r q` $\cdot IQR,Q_3+$ `r q` $\cdot IQR)$, gdzie $Q_1,Q_3$ są pierwszym i trzecim kwartylem, a $IQR$ rozstępem międzykwartylowym. Jednak nie jest to dobre kryterium decyzyjne, ponieważ w przypadku addytywnym mamy mniej obserwacji odstających, jednak największa obserwacja wynosi `r rat.a` przeciętnej wysokości słupka (odległości od średniej), podczas gdy w metodzie multiplikatywnej odległość ta wynosi `r rat.m`.

Sprawdźmy jeszcze czy szereg reszt jest szeregiem stacjonarnym dla modelu addytywnego. Z wcześniejszych wykresów nie mogliśmy zauważyć nic co by wskazywało na niestacjonarność reszt. Dlatego przyjrzyjmy się wykresowi ich funkcji autokorelacji i częściowej autokorelacji.
```{r, fig.cap="Funkcja autokowariancji dla reszt."}
ggAcf(decompose(energia)$random) + ggtitle("")
```
```{r, fig.cap="Funkcja częściowej autokowariancji dla reszt."}
ggPacf(decompose(energia)$random) + ggtitle("")
#sapply(1:4, function(H) adf.test(tmp,k=H)$p.val)
```
```{r,results="hide"}
(tmp=decompose(energia)$random[!sapply(decompose(energia)$random, is.na)])
```
Oba wykresy szybko zanikają do wartości zanikają do wartkości bliskich zeru i regularnych wzorców, zatem nie możemy odrzucić hipotezy o niestacjonarności szeregu. Dodatkowo test ADF (Augmented Dickey-Fuller test) zwrócił p-wartość na poziomie `r adf.test(tmp)$p.val`<0.05 dla wartości opóźnienia $h=$`r adf.test(tmp)$parameter` (podobnie dla mniejszych wartości opóźnień). Zatem mamy podstawy do odrzucenia hipotezy zerowej, głoszącej, że istnieje pierwiastek jednostowy w wielomianie autoregresyjnym (świadczącym o niestacjonarności danych).





\subsubsection{Na podstawie modelu regresji.}
Drugi sposób dekompozycji będzie korzystał z funkcji \verb|tslm| z pakietu \verb|forecast|. Wywołanie funkcji wygląda w następujący sposób.
```{r, eval=FALSE, echo=TRUE}
tslm(energia ~ poly(trend,4,raw=TRUE) + season)
```
W tym przypadku rozpatrujemy przypadek addytywny z: okresowością (odpowiada za to \verb|season|) oraz trendem wielomianowym stopnia 4 (\verb|poly(trend,4, raw=TRUE)|, opcja \verb|raw| oznacza w jakiej postaci chcemy otrzymać współczynniki wielomianu, surowej czy ortogonalnej). Dopasowanie modelu (bez uwzględnienia residuów/losowości) wygląda w następujący sposób.
```{r anim, fig.cap="Dopasowanie modelu do danych.",fig.show="animate"}

# Symetryczna ruchoma średnia
oopt = ani.options(interval=1.5)
st=c(1,2,3,5,8,10,15,25,50,100)
for (k in 1:length(st)) 
{
  tmp=energia-tslm(energia ~ poly(trend,st[k],raw=TRUE) + season)$residuals
  p<-ggplot() +
    geom_line(aes(fortify(energia)$x,fortify(energia)$y, col="Dane",leg="cos"),linewidth=0.5) +     
    geom_line(aes(fortify(tmp)$x,fortify(tmp)$y, col="Dopasowanie"),linewidth=0.5) + 
    xlab("Data") + ylab("Energia") + 
    ggtitle(paste0("Dopasowanie trendu wielomianowego stopnie k=",st[k])) + 
    labs(color='Legenda')
  plot(p)

  ani.pause()
}

ani.options(oopt) 
```
Jak można zauważyć, to dla dużych stopni wielomianu dopasowanie jest dobrze pokrywa krzywą, sprawiając tym samym, że residua są najmniejsze. Jednak przez wybranie zbyt dużego stopnia wielomianu, nie jest możliwe otrzymanie realnej predykcji.

```{r anim_pred, fig.cap="Predykcja na podstawie dopasowanego modelu.",fig.show="animate"}
for (k in 1:length(st)) 
{
  tmp=forecast(tslm(energia ~ poly(trend,k,raw=TRUE) + season),h=40)
  p<-autoplot(tmp) + xlab("Data") + ggtitle(paste0("Predykcja modelu z trendem wielomianowym stopnia k=",k))
  plot(p)

  ani.pause()
}
ani.options(oopt) 
  
```
Jak możemy zauważyć na powyższych animacjach, to pomimo, że wraz z wzrostem stopnia wielomianu polepsza się jego dopasowanie do aktualnych danych, to jego predykcja staje się nierealna. Już dla trendu kwadratowego widzimy zaskakujący spadek, który informuje, że do 2035 roku z dużym prawdopodobieństwem produkcja energii elektrycznej w Polsce spadnie do 0. Scenariusz ten jest mało realny, jedynie dla wielomianu stopnia 1 możemy rozważyć predykcję, która ma możliwość sprawdzenia się w małym okresie czasu.

Sprawdźmy jeszcze czy, przy wyborze trendu liniowego, otrzymaliśmy reszty w postaci szeregu stacjonarnego. Ponownie zacznijmy od przyjrzenia się funkcją acf i pacf.
```{r, fig.cap="Funkcja autokowariancji dla reszt."}
tmp=tslm(energia ~ poly(trend,1,raw=TRUE) + season)$residuals
ggAcf(tmp) + ggtitle("")
```
```{r, fig.cap="Funkcja częściowej autokowariancji dla reszt."}
ggPacf(tmp) + ggtitle("")
#sapply(1:4, function(H) adf.test(tmp,k=H)$p.val)
```
Tym razem możemy zauważyć wolniejsze zanikanie powyższych funkcji oraz możlią regularność w pierwszej z niech. Dlatego wykorzystamy ponownie test ADF do weryfikacji stacjonarności. Tym razem test wykazał p-wartość na poziomie `r adf.test(tmp)$p.val`>0.05 (dla tego samego opóźnienia). Podobnie wygląda sytuacja dla innych opóźnień. Więc nie mamy podstawy do odrzucenia hipotezy o niestacjonarności reszt.

\subsubsection{Na podstawie metody loess.}    
By przetestować ostanią metoda dekompozycji posłużymy się funkcją \verb|stl| z biblioteki \verb|stats|. W tej metodzie będziemy zmieniać dwa parametry \verb|s.window| oraz \verb|t.window|, oznaczające ile obserwacji wykorzystujemy w celu dekompozycji na trend i sezonowość.

```{r anim_stl_tren, fig.cap="Dekompozycja przy pomocy stl dla różnych szerokości okna dla trendu.",fig.show="animate"}

oopt = ani.options(interval=0.9)

t.win=c(1,3,5,11,15,17,23,50,80)
for (t in 1:length(t.win)) 
{
  p<-autoplot(stl(energia, s.window=15,t.window = t.win[t]))+
    xlab("Data") + ggtitle(paste0("Predykcja modelu dla szerokości okna dla trendu t=",t.win[t]))
  plot(p)

  ani.pause()
}

ani.options(oopt) 
```

```{r anim_stl_sen, fig.cap="Dekompozycja przy pomocy stl dla różych szerokości okna dla sezonowości.",fig.show="animate"}

oopt = ani.options(interval=0.9)


s.win=c(1,3,5,11,15,17,23,50,80)
for (s in 1:length(s.win)) 
{
  p<-autoplot(stl(energia, s.window=s.win[s],t.window = 15))+
    xlab("Data") + ggtitle(paste0("Predykcja modelu dla szerokości okna dla trendu t=15\n oraz dla sezonowości s=",s.win[s]))
  plot(p)

  ani.pause()
}

ani.options(oopt) 



```

Jak można zauważyć na animacjach, dla małych wielkości okien otrzymujemy nie zadawalające wyniki, niezależnie czemu odpowiadała wielkość tego okna. Jednak dla dużych wartości problem ten powstaje jedynie dla trendu. W przypadku sezonowości to od wielkości okna ok. 11, zwiększanie wartości \verb|s.window| nie polepszało, ani nie pogarszało, jakości dekompozycji. 

Możemy sprawdzić, czy szereg reszt jest szeregiem stacjonarnym. Wykresy acf i pacf dla wielkości okien równych 15, prezentują się następująco.

```{r, fig.cap="Funkcja autokowariancji dla reszt."}
tmp<-stl(energia, s.window=15,t.window = 15)$time.series[,3]
ggAcf(decompose(energia)$random) + ggtitle("")
```
```{r, fig.cap="Funkcja częściowej autokowariancji dla reszt."}
ggPacf(decompose(energia)$random) + ggtitle("")
#sapply(1:4, function(H) adf.test(tmp,k=H)$p.val)
```
W tym przypadku nie widzimy rzadnej nieregularności oraz obie funkcje szybko zanikają do zera. Sprawdźmy w jak wyglądają wyniki testu ADF dla poszczególnych wartości.

```{r}
s.win=c(1,3,5,15,21,43)
#t.win=c(4,8,12,14,20,40)
t.win=c(3,5,9,13,15,21,43)

#tmp=matrix(apply(crossing(s.win,t.win),1,function(X) adf.test(stl(energia, s.window=X[1],t.window = X[2])$time.series[,3])$p.val), nrow=length(s.win))

#tmp=matrix(apply(crossing(s.win,t.win),1,function(X) X[1]/X[2]), nrow=length(s.win))
# Pierwsza wartość (s) to kolumny, druga (t) to wiersze. -> X[1] to wielkość okna dla sezonowości


#rownames(tmp)<-s.win
#colnames(tmp)<-t.win
#tmp


############ Korzystając z crossing dziwne rzeczy się działy
s.win=c(1,3,5,7,15,21)
t.win=c(3,5,9,13,15,21,43)

tmp=zeros(length(s.win),length(t.win))
for(s in 1:length(s.win)){
  for(t in 1:length(t.win)){
    tmp[s,t]=adf.test(stl(energia, s.window=s.win[s],t.window = t.win[t])$time.series[,3])$p.val
  }
}
tmp=data.frame(round(tmp,3))
colnames(tmp)<-t.win
rownames(tmp)<-s.win

col=apply(tmp, 1,
           function(X) sapply(X, 
                              function(Y) if(Y>=0.05) "#FF0000" else "#000000"))



tmp %>%
  kbl(caption="\\label{tab:adf_3}Tablica p-wartości dla test ADF. Kolumny informują o wielkości rozpatrywanego okna dla trendu, podczas gdy wiersze odpowiadają za okno sezonowości.") %>%
  kable_paper(full_width = F) %>%
  column_spec(2, color = col[1,]) %>%
  column_spec(3, color = col[2,]) %>%
  column_spec(4, color = col[3,]) %>%
  column_spec(5, color = col[4,]) %>%
  column_spec(6, color = col[5,]) %>%
  column_spec(7, color = col[6,]) %>%
  column_spec(8, color = col[7,]) %>%
  kable_styling(latex_options = "HOLD_position")
```
Jak możemy zauważyć, dzięki powyższej tabeli, dla większości rozmiarów okna dla średniej (przedział 5-21) mamy przesłanki do odrzucenia hipotezy o niestacjonarności. Co ciekawe, dla wartości okna $t=43$, decydujące słowo ma również wielkość okna dla sezonowości.






\subsection{Transformacja Boxa-Coxa.}
Możemy sprawdzić, jak dane będą się zachowywać po nałożeniu na nie transformacji Boxa-Coxa. Porównaliśmy transformacje dla dwóch różnych wartości $\lambda$. Pierwsza transformacja była logarytmiczna ($\lambda=0$), natomiast dla drugiej transformacji, wartość $\lambda$ została dobrana automatycznie, według algorytmu zaimplementowanego w \verb|R|. Korzystając z metody Guerrero do wyboru automatycznego parametru otrzymaliśmy lambda= `r BoxCox.lambda(energia)`, czyli górną granicę narzuconą przez funkcję. Po odblokowaniu górnego przedziału wartość ta wynosi `r BoxCox.lambda(energia, upper=3)`.

Wcześniej, w pierwszej oraz trzeciej metodzie otrzymaliśmy z dużym prawdopodobieństwem reszty w postaci szeregu stacjonarnego, w przeciwieństwie do metody drugiej. Dlatego poniżej pokażemy jedynie wyniki połączenia transformaty B-C z metodą wykorzystującą funkcję \verb|tslm|. Jednak w tym przypadku rozpatrywaliśmy trend kwadratowy zamiast liniowego, jak poprzednio. W tabeli poniżej zamieściliśmy wyniki testu ADF różnych transformacji oraz opóźnień. W pierwszej kolumnie znajdują się dane nieprzetransformowane.   

```{r}
k=2
tmp2=tslm(log(energia) ~ poly(trend,k,raw=TRUE) + season)
tmp3=tslm(BoxCox(energia,lambda = 0.75) ~ poly(trend,k,raw=TRUE) + season)
tmp4=tslm(BoxCox(energia,lambda = "auto") ~ poly(trend,k,raw=TRUE) + season)
tmp5=tslm(BoxCox(energia,lambda = BoxCox.lambda(energia,upper=3)) ~ poly(trend,k,raw=TRUE) + season)
tmp1=tslm(energia ~ poly(trend,k,raw=TRUE) + season)

p1=sapply(1:4,function(X) adf.test(tmp1$residuals, k=X)$p.val)
p2=sapply(1:4,function(X) adf.test(tmp2$residuals, k=X)$p.val)
p3=sapply(1:4,function(X) adf.test(tmp3$residuals, k=X)$p.val)
p4=sapply(1:4,function(X) adf.test(tmp4$residuals, k=X)$p.val)
p5=sapply(1:4,function(X) adf.test(tmp5$residuals, k=X)$p.val)

tmp=matrix(c(p1,p2,p3,p4,p5),nrow=4)

#all(tmp[,1]==p1)
tmp=data.frame(tmp)



colnames(tmp)<-c("Dane", "Log", round(BoxCox.lambda(energia),3),round(BoxCox.lambda(energia,method = "loglik"), 3) , round(BoxCox.lambda(energia,upper=3),3))

rownames(tmp)<-c("1","2","3","4")


col=apply(tmp, 1,
           function(X) sapply(X, 
                              function(Y) if(Y<=0.05) "#00FF00" else "#000000"))



tmp %>%
  kbl(caption="\\label{tab:adf_BC}Tablica p-wartości dla test ADF. Wiersze to wielkość opóźnienia, natomiast kolumny to rodzaj przekształcenia Boxa-Coxa") %>%
  kable_paper(full_width = F) %>%
  column_spec(1, color = col[1,]) %>%
  column_spec(2, color = col[2,]) %>%
  column_spec(3, color = col[3,]) %>%
  column_spec(4, color = col[4,]) %>%
  column_spec(5, color = col[5,]) %>%
  kable_styling(latex_options = "HOLD_position")
```
Możemy zwrócić uwagę na zielone wartości w tabeli. Są to wartości uzyskane dla danych przetransformowanych przy użyciu transformacji Boxa-Coxa z parametrem $\lambda$ dobranym przy pomocy jednej z zaimplementowanych metod (z odblokowanym górnym ograniczeniem). W ten sposób otrzymaliśmy model, dla którego mamy świadka postaci opóźnienia $h=1$, który świadczy o stacjonarności otrzymanych reszt. Takich informacji nie mieliśmy dla czystych danych (bez użycia B-C). Przyjrzyjmy się jeszcze wykresom acfi i pacf dla ostatniej z transformacji ($\lambda=2.507$).  

```{r, results="asis", fig.cap="Wykres acf dla danych po użyciu transformacji B-C."}
l=BoxCox.lambda(energia,upper=3)
tmp=tslm(BoxCox(energia,lambda=l) ~ poly(trend,2,raw=TRUE) + season)$residuals
ggAcf(tmp)+ggtitle("")
```

```{r, results="asis", fig.cap="Wykres pacf dla danych po użyciu transformacji B-C."}
ggPacf(tmp)+ggtitle("")
```
Porównując to z poprzednimi wykresami, po transformacji możliwa regularność stała się mniej zauważalna, jednak może to być spowodowane również zwiększeniem stopnia wielomianu trendu.

\subsection{Różnicowanie.}
Ostatnią metodą jaką chcielibyśmy rozpatrzyć jest różnicowanie sezonowe. Ponieważ wykres sezonowy \ref{fig:seasonplot} potwierdził zależność sezonową z odstępem $h=12$ to będziemy właśnie rozpatrywać dane postaci $Z_t=X_t-X_{t-12}$, gdzie $X_t$ to rozpatrywane dane - energia. Poniżej przedstawiliśmy otrzymane dane na wykresie.

```{r, fig.cap="Wykres danych po zróżnicowaniu z opóźnieniem h=12"}
res=diff(energia,lag=12)

autoplot(res)

########################## Próby dostania lepszych wyników (kolejne różnicowanie oraz sprawdzanie ilorazów)
# k=12
# pes=diff(res,lag=k)
# pes=res[-1]/res[-length(res)]
# C=max(abs(res))/max(abs(pes))
# 
# ggplot() +
#     geom_line(aes(fortify(res)$x,fortify(res)$y, col="Zróżnicowanie z krokiem 12"),linewidth=0.7) +     
#     geom_col() +
#       scale_y_continuous(name="dwa", sec.axis = sec_axis(~.*(1/C), name="tak")) +
#     geom_line(aes(fortify(res)$x[-1],C*pes, col=paste0("Ponownie zróżnicowane\n dane z krokiem ",k)),linewidth=0.5,linetype = "longdash") + 
#     xlab("Data") + ylab("Energia") + 
#     labs(color='Legenda')
```
Na wykresie możemy zauważyć zachowanie sugerujące, że pozostał jednak jakiś trend. Możemy spojrzeć jeszcze na wykres funkcji PACF.
```{r, fig.cap="Wykres pacf dla zróżnicowanych danych."}
diff.p<-adf.test(res)$p.val
ggPacf(res)+ggtitle("")
```
Możemy zauważyć znaczące wychylenie od zera dla opóźnienia $h=14$, wskazujące, że nie mamy do czynienia z szeregiem stacjonarnym. Wykonaliśmy jeszcze test ADF, który zwrócił nam p-wartość na poziomie `r diff.p` zatem nie mamy podstaw do odrzucenia hipotezy o niestacjonarności reszt. Podobnie próbowaliśmy ponownie różnicować rozpatrywane dane oraz sprawdzaliśmy jak zachowają się, gdy rozpatrzymy iloraz w postaci $Z_t/Z_{t-1}$, jednak otrzymane wyniki nie były zadowalające. 


\subsection{Podsumowanie}
Spośród rozpatrywanych metod dekompozycji najlepiej poradziły sobie związane z funkcjami \verb|decompose| oraz \verb|stl|. Jednak metoda drug, związana z funkcją \verb|tslm| próbowała dopasować wzór analityczny do trendu. Na podstawie tej metody pokazaliśmy, że transformacja Boxa-Coxa może poprawić nasze dane -- pozwoliła otrzymać szereg reszt, który przeszedł test na stacjonarność (ADF test) dla opóźnienia $h=1$. Rozpatrzyliśmy jeszcze dane po zróżnicowaniu sezonowym oraz z różnymi opóźnieniami. Wyniki okazały się mniej zadowalające niż otrzymane pozostałymi metodami, ale jest to metoda najprostsza w implementacji oraz najmniej zmieniająca dane podczas transformacji (nie rozdziela je osobna na trend, sezonowość itp.). 

\section{Zastosowanie wskaźników analizy technicznej w analizie szeregów czasowych.}
W celu analizy rozpatrujemy akcje firmy KGHM Polska Miedź z okresu od 30 kwietnia 2020 do dania pisania tego raportu tj. 30 kwiecień 2023 roku. Dane prezentują się następująco.
```{r}
#getSymbols(Symbols="CPER" , src="yahoo", from='2013-04-12', to='2023-04-12')
getSymbols(Symbols="KGH.WA" , src="yahoo", from='2020-04-30')
kghm = KGH.WA#$CPER.Close #tail(CPER, 300)
chartSeries(kghm)
```
<!--
W naszych danych znajduję się `r sum(time(kghm)[-1]-time(kghm)[-length(time(kghm))]==2)+sum(time(kghm)[-1]-time(kghm)[-length(time(kghm))]>3)` brakujących danych (przy założeniu 5 dniowego tygodnia). Spowodowane jest to nie funkcjonowaniem giełdy w święta oraz wybrane dni. Daltego sporządziliśmy również wykres zmian tygodniowych, który wygląda następująco.
```{r}
chartSeries(to.weekly(kghm))

```
-->
W danych (cenach zamknięcia) znaleźliśmy `r sum(sapply(Cl(kghm), is.na))` brakujących danych, ale postanowiliśmy zignorować tą informację.
```{r}
kghm=kghm[!sapply(Cl(kghm), is.na)]
```
Możemy teraz przystąpić do analizy technicznej. Na poniższym wykresie zamieściliśmy wszystkie wyniki dla podstawowych parametrów (według zaimplementowanych algorytmów). 
```{r, fig.height=7, results="hide"}
#candleChart(copper, TA=c(addBBands(), addMACD(),addSMI(), addADX()))#, subset = '2018-01::')
chartSeries(kghm, TA=c(addBBands(), addMACD(),addSMI()), type="auto")#, subset = '2018-01::')



```
Na wykresie zamieszczone zostały wskaźniki takie jak:
\begin{itemize}
  \item Wstęga bolingera --  dwie czerwone i przerywane linie nałożone na pierwszy wykres. Jeśli cena spadnie poniżej dolnej linii jest to sygnał do kupna, jeśli przednie górną, to otrzymujemy sygnał do sprzedaży. Podczas analizy rozważymy zmianę dwóch parametrów w funkcji
  \begin{itemize}
    \item $n$ -- odpowiadającą za liczbę okresów ruchomej średniej,
    \item $sd$ -- odchylenie standardowe -- odpowiadające za wielkość przedziałów.
  \end{itemize}
  \item MACD -- Moving Avrage Convergence Diverfence -- jest to wskaźnik dynamiki trendów, który pokazuje związek pomiędzy dwiema średnimi kroczącymi. Sygnał kupna jest generowany, gdy linia MACD przetnie linię sygnalną od dołu, a sygnał sprzedaży generowany jest wtedy, kiedy linia MACD przetnie linię sygnalną od góry.
  \item SMI -- Stochastic Momentum Index -- oblicza odległość między aktualną ceną zamknięcia w stosunku do miediany górnego/dolnego przedziału cenowego. Podczas analizy rozpatrzymy zmienianie parametru $n$ odpowiedzialnego za długość rozważanego okresu.
\end{itemize}

Możemy teraz spojrzeć na ich interpretację. W naszych danych mamy duże okresy bardzo gwałtownych zmian, co jest do przewidzenia, zważając, że jest to okres pandemii. Dlatego wstęga Bollingera słabo nadaje się w tym przypadku. Każe sprzedawać, podczas gdy cena będzie dalej rosła, a kupować gdy cena ciągle spada. Oczywiście zdarzają się momenty, gdy wstęga dobrze nam doradziła, przykładowo w marcu 2021 roku. Podobnie jest z kolejnymi metodami. W wielu przypadkach źle oceniły sytuację. Jeżeli jednak ograniczymy się jedynie do ostatnich miesięcy, możemy zauważyć, że metoda MACD na przełomie stycznia i lutego nakazała nam sprzedaż, co rzeczywiście się nam opłacało w tym okresie. Podobnie z resztą metoda SMI.


\subsubsection{Wstęga Bolingera}
 Porównajmy Wstęgę Bolingera na poniższych animacjach.
```{r anim_BBand_n, fig.cap="Wstęga Bolingera dla różnych wartości parametrów.",fig.show="animate", fig.width=6, fig.height=4}

oopt = ani.options(interval=0.9)


n.win=c(5,10,15,20,25,30,35,40)
for (n in 1:length(n.win)) 
{
  chartSeries(kghm, TA=c(addBBands(n=n.win[n])), type="auto", name=paste0("Wstęga Bollingera dla n=",n.win[n]))

  ani.pause()
}
ani.options(oopt) 
```

```{r anim_BBand_sd, fig.cap="Wstęga Bolingera dla różnych wartości parametrów.",fig.show="animate", fig.width=6, fig.height=4}

sd.win=c(1,1.5,2,2.5,3,3.5,4,5)
for (i in 1:length(n.win)) 
{
  chartSeries(kghm, TA=c(addBBands(sd=sd.win[i])), type="auto", name=paste0("Wstęga Bollingera dla sd=",sd.win[i]))

  ani.pause()
}

ani.options(oopt) 

```
Możemy zauważyć, że wraz ze wzrostem parametry $n$ zwiększa się wielkość wstęgi (odległość między obiema liniami), ale również przesuwa się delikatnie w prawo oraz staje się bardziej wygładzona. Natomiast zmiana parametru $sd$ w głównej mierze zwiększa wielkość wstęgi.

\subsubsection{MACD}
Rozpatrzymy teraz jak zachowa się funkcja \verb|MACD| w przypadku zmiany jej parametrów.
```{r anim_MACD_slow, fig.cap="MACD dla różnych wartości parametrów.",fig.show="animate", fig.width=6, fig.height=4}

slow.win=c(13,15,18,23,26,30,40)
fast.win=c(2,3,5,8,13,21,25)
for (i in 1:length(slow.win)) 
{
  
  p<-autoplot(MACD(Cl(kghm),nSlow=slow.win[i])) + xlab(paste0("Wykres dla nSlow=",slow.win[i]))
  plot(p)
  ani.pause()
}

ani.options(oopt) 

```

```{r anim_MACD_fast, fig.cap="MACD dla różnych wartości parametrów.",fig.show="animate", fig.width=6, fig.height=4}

slow.win=c(13,15,18,23,26,30,40)
fast.win=c(2,3,5,8,13,21,25)
for (i in 1:length(fast.win)) 
{
  p<-autoplot(MACD(Cl(kghm),nFast=fast.win[i])) + xlab(paste0("Wykres dla nFast=",fast.win[i]))
  plot(p)
  ani.pause()
}

ani.options(oopt) 

```

Jak widzimy, podobnie jak w przypadku wstęgi Bollingera i parametru $n$, parametry $nSlow$ i $nFast$ zwiększają wygładzenia krzywych. Jednak można zauważyć, że zwiększając wartość parametru $nSlow$ zwiększamy maksymalne wartości funkcji macd oraz signal. Natomiast dla większych parametrów $nFast$ działanie jest odwrotne, wraz z zwiększeniem parametru maleją wartości obu funkcji.


\subsubsection{SMI}
Ostatnią rozpatrywaną funkcją będzie \verb|SMI|. Wyniki prezentują się następująco
```{r anim_SMI, fig.cap="SMI dla różnych wartości parametrów.",fig.show="animate", fig.width=6, fig.height=4}

n.win=c(2,3,5,8,13,21,34)
for (i in 1:length(n.win)) 
{
  p<-autoplot(SMI(Cl(kghm),n=n.win[i])) + xlab(paste0("Wykres dla n=",n.win[i]))
  plot(p)
  ani.pause()
}

ani.options(oopt) 

```
Również w tym przypadku widzimy, że zmiana parametru $n$ zwiększa wygładzenie funkcji oraz zwiększenie wartości obu funkcji, analogicznie jak działo się w przypadku parametru $nSlow$. 












